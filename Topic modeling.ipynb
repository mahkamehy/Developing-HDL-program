{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    back_quotes = re.compile('<code>(.|\\n)*?</code>')\n",
    "    cleantext = re.sub(back_quotes,'', raw_html)\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', cleantext)\n",
    "    rem_url = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', cleantext, flags=re.MULTILINE)\n",
    "    rem_num = re.sub('[^a-zA-Z ]', ' ', rem_url)\n",
    "    return rem_num\n",
    "       \n",
    "def tokenization(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace() | token.is_punct :\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "\n",
    "def get_stem(word):\n",
    "    porter = PorterStemmer()\n",
    "    return porter.stem(word)\n",
    "    \n",
    "def get_lemma(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path_posts):\n",
    "    posts = pd.read_csv(path_posts)\n",
    "    posts.creationdate = pd.to_datetime(posts.creationdate  , format='%Y-%m-%d', errors='ignore')\n",
    "    posts.AcceptedAnswerdate = pd.to_datetime(posts.AcceptedAnswerdate  , format='%Y-%m-%d', errors='ignore')\n",
    "    posts.ACCanswerBody.fillna(' ',inplace=True)\n",
    "\n",
    "    posts['Text'] = posts.title +' '+ posts.questionBody  +' '+ posts.ACCanswerBody \n",
    "\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = read_file('finalresult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    text = cleanhtml(text)\n",
    "    tokens = tokenization(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [get_stem(token) for token in tokens]\n",
    "#     tokens = [get_lemma(token) for token in tokens]\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    tokens = [ele for ele in tokens if all(ch not in ele for ch in char_list)] \n",
    "#     tokens = [token for token in tokens if len(token) >=4]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = result['Text'].map(lambda x : prepare_text_for_lda(x))\n",
    "# Print out the first rows of papers\n",
    "text_data.head()\n",
    "text_data.to_csv('final_result_data_processing.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=30) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=30)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# Remove Stop Words\n",
    "texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in data_words]\n",
    "# Form Bigrams\n",
    "texts = [bigram_mod[doc] for doc in texts]\n",
    "# Form trigrams\n",
    "texts = [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "texts_out = []\n",
    "for sent in texts:\n",
    "    doc = nlp(\" \".join(sent)) \n",
    "    texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "# remove stopwords once more after lemmatization\n",
    "# texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_processing_bigram_trigram.csv','w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(texts_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(texts_out)\n",
    "# Create Corpus\n",
    "texts = texts_out\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "\n",
    "    model_results = {\n",
    "                 'Topics': [],\n",
    "#                  'Alpha': [],\n",
    "                 'model': [],\n",
    "                 'Coherence': []                    \n",
    "                    }\n",
    "    # Alpha parameter\n",
    "    alpha = list(np.arange(0.01, 1, 0.01))\n",
    "    if 1==1:\n",
    "        pbar = tqdm.tqdm(total=(limit-start))  \n",
    "        for num_topics in range(start, limit, step):\n",
    "#             for a in alpha:\n",
    "                model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary,\n",
    "                                                           optimize_interval=10 , \n",
    "                                                          iterations=5000,\n",
    "                                                         random_seed=100\n",
    "                                                        )\n",
    "                model_results['model'].append(model)\n",
    "                coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "                model_results['Coherence'].append(coherencemodel.get_coherence())\n",
    "                model_results['Topics'].append(num_topics)\n",
    "#                 model_results['Alpha'].append(a)                \n",
    "                pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 35/35 [2:33:43<00:00, 263.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# Can take a long time to run.\n",
    "model_list = compute_coherence_values(dictionary=id2word, corpus=corpus, \n",
    "                                                        texts=texts_out, start=5, limit=40, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.wrappers.ldamallet.LdaMallet at 0x2d2fa8a7ac0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list['model'][model_list['Coherence'].index(max(model_list['Coherence']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>model</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>&lt;gensim.models.wrappers.ldamallet.LdaMallet ob...</td>\n",
       "      <td>0.453466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topics                                              model  Coherence\n",
       "6      11  <gensim.models.wrappers.ldamallet.LdaMallet ob...   0.453466"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tuning = pd.DataFrame.from_dict(model_list)\n",
    "result_tuning[result_tuning.index==result_tuning.Coherence.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'tuned_model_lda'\n",
    "lda_model = model_list['model'][model_list['Coherence'].index(max(model_list['Coherence']))]\n",
    "with open(filename, 'wb') as file:  \n",
    "    pickle.dump(lda_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final paramater for topic modeling\n",
    "topics = 9\n",
    "alpha = 0.9\n",
    "beta = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5,\n",
      "  [('datum', 0.06570260924237661),\n",
      "   ('bit', 0.06224457717698837),\n",
      "   ('send', 0.04825526563973593),\n",
      "   ('byte', 0.027978623074504872),\n",
      "   ('receiv', 0.0242062244577177),\n",
      "   ('serial', 0.022320025149324112),\n",
      "   ('start', 0.01634706067274442),\n",
      "   ('packet', 0.014460861364350833),\n",
      "   ('charact', 0.014303678088651368),\n",
      "   ('uart', 0.011945928953159385)]),\n",
      " (0,\n",
      "  [('read', 0.1004),\n",
      "   ('write', 0.08266666666666667),\n",
      "   ('datum', 0.05106666666666667),\n",
      "   ('address', 0.044533333333333334),\n",
      "   ('memori', 0.03573333333333333),\n",
      "   ('ram', 0.032266666666666666),\n",
      "   ('store', 0.0284),\n",
      "   ('regist', 0.025333333333333333),\n",
      "   ('block', 0.016666666666666666),\n",
      "   ('instruct', 0.015066666666666667)]),\n",
      " (1,\n",
      "  [('type', 0.061824605153782214),\n",
      "   ('declar', 0.04041978387364921),\n",
      "   ('function', 0.040108063175394844),\n",
      "   ('vhdl', 0.025976724854530342),\n",
      "   ('error', 0.02514546965918537),\n",
      "   ('constant', 0.02348295926849543),\n",
      "   ('variabl', 0.01818370739817124),\n",
      "   ('vector', 0.014235245220282626),\n",
      "   ('defin', 0.012884455527847049),\n",
      "   ('size', 0.011741479634247714)]),\n",
      " (6,\n",
      "  [('state', 0.052583779856507126),\n",
      "   ('output', 0.033511942602851695),\n",
      "   ('input', 0.030696576151121605),\n",
      "   ('lead', 0.020343293070565798),\n",
      "   ('reset', 0.020343293070565798),\n",
      "   ('display', 0.020252474797929344),\n",
      "   ('set', 0.019889201707383525),\n",
      "   ('high', 0.01898101898101898),\n",
      "   ('switch', 0.017800381436745075),\n",
      "   ('start', 0.017164653528289893)]),\n",
      " (10,\n",
      "  [('output', 0.06736526946107785),\n",
      "   ('input', 0.057100085543199314),\n",
      "   ('port', 0.047369546621043625),\n",
      "   ('connect', 0.0294054747647562),\n",
      "   ('wire', 0.028763900769888794),\n",
      "   ('modul', 0.026625320786997433),\n",
      "   ('warn', 0.025342172797262617),\n",
      "   ('drive', 0.02256201881950385),\n",
      "   ('signal', 0.022348160821214713),\n",
      "   ('pin', 0.020958083832335328)]),\n",
      " (8,\n",
      "  [('clock', 0.1332325037811082),\n",
      "   ('time', 0.043379623264127594),\n",
      "   ('cycl', 0.034717448095696414),\n",
      "   ('output', 0.025092809019661762),\n",
      "   ('input', 0.024199092534029975),\n",
      "   ('design', 0.021242953389247903),\n",
      "   ('pul', 0.015399422521655439),\n",
      "   ('signal', 0.014780695723910353),\n",
      "   ('high', 0.011274577203354874),\n",
      "   ('regist', 0.010930840093496494)]),\n",
      " (7,\n",
      "  [('bit', 0.13111413043478262),\n",
      "   ('number', 0.05600845410628019),\n",
      "   ('output', 0.025362318840579712),\n",
      "   ('input', 0.02332427536231884),\n",
      "   ('result', 0.017512077294685992),\n",
      "   ('shift', 0.016153381642512076),\n",
      "   ('width', 0.015172101449275362),\n",
      "   ('implement', 0.014568236714975846),\n",
      "   ('vector', 0.014190821256038648),\n",
      "   ('add', 0.012454710144927536)]),\n",
      " (9,\n",
      "  [('file', 0.05417287102035028),\n",
      "   ('design', 0.036871587605474015),\n",
      "   ('find', 0.019570304190597746),\n",
      "   ('vhdl', 0.01928667659363256),\n",
      "   ('program', 0.017372190314117564),\n",
      "   ('project', 0.017301283414876266),\n",
      "   ('work', 0.01723037651563497),\n",
      "   ('tool', 0.017159469616393676),\n",
      "   ('hdl', 0.016166773027015528),\n",
      "   ('test', 0.012692334964192016)]),\n",
      " (3,\n",
      "  [('design', 0.040279849786511654),\n",
      "   ('logic', 0.02633880343639076),\n",
      "   ('synthe', 0.023560882761458922),\n",
      "   ('implement', 0.020268532331910078),\n",
      "   ('exampl', 0.016307423221359123),\n",
      "   ('case', 0.016255980245897424),\n",
      "   ('differ', 0.014249704202891095),\n",
      "   ('thing', 0.013272287669118782),\n",
      "   ('code', 0.013117958742733679),\n",
      "   ('find', 0.011266011626112455)]),\n",
      " (4,\n",
      "  [('simul', 0.06374005559283044),\n",
      "   ('code', 0.047445605290903865),\n",
      "   ('error', 0.03345154797277868),\n",
      "   ('work', 0.030432282181539348),\n",
      "   ('problem', 0.026454519313716094),\n",
      "   ('output', 0.02051183743889581),\n",
      "   ('write', 0.02041598773123742),\n",
      "   ('expect', 0.017252947378510495),\n",
      "   ('vhdl', 0.017013323109364518),\n",
      "   ('follow', 0.016102750886609795)])]\n",
      "\n",
      "Coherence Score:  0.4534657752351379\n"
     ]
    }
   ],
   "source": [
    "# # Show Topics\n",
    "# LDAModel = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=topics, \n",
    "#                                            random_state=100,\n",
    "#                                            chunksize=10000,\n",
    "#                                            passes=10,\n",
    "#                                            alpha=alpha,\n",
    "#                                            eta=beta,\n",
    "#                                           per_word_topics=True,\n",
    "#                                           )\n",
    "with open('tuned_model_lda','rb') as model :\n",
    "    LDAModel = pickle.load(model)\n",
    "pprint(LDAModel.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=LDAModel, texts=texts_out, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "                \n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords ]), ignore_index=True)               \n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts.Text)\n",
    "    Id = pd.Series(texts.id)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents,Id], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=LDAModel, corpus=corpus, texts=result[['Text','id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords.groupby('Dominant_Topic').size().reset_index(name='Frequency').to_excel('topics_distribution.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Sentence_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text','id']\n",
    "df_dominant_topic_final = pd.merge(result ,df_dominant_topic, on='id',how='inner' )\n",
    "df_dominant_topic_final.to_csv('Topic_modeling_result_HDL.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df_dominant_topic_final.groupby('Dominant_Topic').size().reset_index(name='Frequency')\n",
    "# Calculate Percentage\n",
    "df_freq['percentage'] = (df_freq['Frequency'] / \n",
    "                      df_freq['Frequency'].sum()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic_final.Dominant_Topic = 'Topic_'+ df_dominant_topic_final.Dominant_Topic.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2019\\anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py:336: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "df_dict = {}\n",
    "\n",
    "for topic in df_dominant_topic_final.Dominant_Topic.unique():\n",
    "    topic_df = df_dominant_topic_final[df_dominant_topic_final['Dominant_Topic'] == topic]\n",
    "    df_dict[topic] = topic_df\n",
    "    \n",
    "def save_xlsx(df_dict, path):\n",
    "    \"\"\"\n",
    "    Save a dictionary of dataframes to an excel file, with each dataframe as a seperate page\n",
    "    \"\"\"\n",
    "\n",
    "    with pd.ExcelWriter(path) as writer:\n",
    "        for key in df_dict:\n",
    "            df_dict[key].to_excel(writer, key, index=False)\n",
    "\n",
    "    writer.save()\n",
    "save_xlsx(df_dict, 'Topic_modeling_results_per_topic.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
