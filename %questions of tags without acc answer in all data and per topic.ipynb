{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbeb56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "df0 = pd.read_csv (r'Topic_modeling_result_HDL.csv',parse_dates=['AcceptedAnswerdate','creationdate'])\n",
    "print(len(df0.index))\n",
    "\n",
    "df01 = (df0.assign(tagnames = df0['tagnames'].str.split(','))\n",
    "         .explode('tagnames')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "print(len(df01.index))\n",
    "# print(len(df01.index))\n",
    "value_list = ['vhdl']\n",
    "df_dominant_topic_final = df01[df01['tagnames'].isin(value_list)]\n",
    "\n",
    "print(len(df_dominant_topic_final.index))\n",
    "###########################################\n",
    "df_dominant_topic_final.ACCanswerBody.isna().sum()\n",
    "\n",
    "df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n",
    "\n",
    "\n",
    "\n",
    "df_dominant_topic_final.IsAcceptedAnswer.value_counts(normalize=True)      \n",
    "\n",
    "accepted_answers_percentage = df_dominant_topic_final.groupby(['Dominant_Topic','IsAcceptedAnswer']).size().reset_index(name='count')\n",
    "# Change: groupby state_office and divide by sum\n",
    "tmp_df = accepted_answers_percentage.groupby('Dominant_Topic').agg({'count': 'sum'}).reset_index()\n",
    "tmp_df = pd.merge(accepted_answers_percentage , tmp_df , on='Dominant_Topic' ,how='inner')\n",
    "tmp_df['percentage'] = (tmp_df['count_x']/tmp_df['count_y'])*100\n",
    "accepted_answers_percentage = tmp_df[['Dominant_Topic','IsAcceptedAnswer','percentage']]\n",
    "not_accepted_answer = accepted_answers_percentage[accepted_answers_percentage['IsAcceptedAnswer']==False]\n",
    "not_accepted_answer.to_excel('Not accepted answer percentage per topic.xlsx',index=False)\n",
    "print(not_accepted_answer)\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x = 'Dominant_Topic', y = 'percentage', data = not_accepted_answer,\n",
    "            palette = 'Blues', edgecolor = 'w')\n",
    "\n",
    "\n",
    "\n",
    "                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81491b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "df0 = pd.read_csv (r'Topic_modeling_result_HDL.csv',parse_dates=['AcceptedAnswerdate','creationdate'])\n",
    "print(len(df0.index))\n",
    "\n",
    "df01 = (df0.assign(tagnames = df0['tagnames'].str.split(','))\n",
    "         .explode('tagnames')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "print(len(df01.index))\n",
    "# print(len(df01.index))\n",
    "value_list = ['verilog']\n",
    "df_dominant_topic_final = df01[df01['tagnames'].isin(value_list)]\n",
    "\n",
    "print(len(df_dominant_topic_final.index))\n",
    "###########################################\n",
    "df_dominant_topic_final.ACCanswerBody.isna().sum()\n",
    "\n",
    "df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n",
    "\n",
    "\n",
    "\n",
    "df_dominant_topic_final.IsAcceptedAnswer.value_counts(normalize=True)      \n",
    "\n",
    "accepted_answers_percentage = df_dominant_topic_final.groupby(['Dominant_Topic','IsAcceptedAnswer']).size().reset_index(name='count')\n",
    "# Change: groupby state_office and divide by sum\n",
    "tmp_df = accepted_answers_percentage.groupby('Dominant_Topic').agg({'count': 'sum'}).reset_index()\n",
    "tmp_df = pd.merge(accepted_answers_percentage , tmp_df , on='Dominant_Topic' ,how='inner')\n",
    "tmp_df['percentage'] = (tmp_df['count_x']/tmp_df['count_y'])*100\n",
    "accepted_answers_percentage = tmp_df[['Dominant_Topic','IsAcceptedAnswer','percentage']]\n",
    "not_accepted_answer = accepted_answers_percentage[accepted_answers_percentage['IsAcceptedAnswer']==False]\n",
    "not_accepted_answer.to_excel('Not accepted answer percentage per topic.xlsx',index=False)\n",
    "print(not_accepted_answer)\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x = 'Dominant_Topic', y = 'percentage', data = not_accepted_answer,\n",
    "            palette = 'Blues', edgecolor = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d919d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "df0 = pd.read_csv (r'Topic_modeling_result_HDL.csv',parse_dates=['AcceptedAnswerdate','creationdate'])\n",
    "print(len(df0.index))\n",
    "\n",
    "df01 = (df0.assign(tagnames = df0['tagnames'].str.split(','))\n",
    "         .explode('tagnames')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "print(len(df01.index))\n",
    "# print(len(df01.index))\n",
    "value_list = ['system-verilog']\n",
    "df_dominant_topic_final = df01[df01['tagnames'].isin(value_list)]\n",
    "\n",
    "print(len(df_dominant_topic_final.index))\n",
    "###########################################\n",
    "df_dominant_topic_final.ACCanswerBody.isna().sum()\n",
    "\n",
    "df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n",
    "\n",
    "\n",
    "\n",
    "df_dominant_topic_final.IsAcceptedAnswer.value_counts(normalize=True)      \n",
    "\n",
    "accepted_answers_percentage = df_dominant_topic_final.groupby(['Dominant_Topic','IsAcceptedAnswer']).size().reset_index(name='count')\n",
    "# Change: groupby state_office and divide by sum\n",
    "tmp_df = accepted_answers_percentage.groupby('Dominant_Topic').agg({'count': 'sum'}).reset_index()\n",
    "tmp_df = pd.merge(accepted_answers_percentage , tmp_df , on='Dominant_Topic' ,how='inner')\n",
    "tmp_df['percentage'] = (tmp_df['count_x']/tmp_df['count_y'])*100\n",
    "accepted_answers_percentage = tmp_df[['Dominant_Topic','IsAcceptedAnswer','percentage']]\n",
    "not_accepted_answer = accepted_answers_percentage[accepted_answers_percentage['IsAcceptedAnswer']==False]\n",
    "not_accepted_answer.to_excel('Not accepted answer percentage per topic.xlsx',index=False)\n",
    "print(not_accepted_answer)\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x = 'Dominant_Topic', y = 'percentage', data = not_accepted_answer,\n",
    "            palette = 'Blues', edgecolor = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ad2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "df0 = pd.read_csv (r'Topic_modeling_result_HDL.csv',parse_dates=['AcceptedAnswerdate','creationdate'])\n",
    "print(len(df0.index))\n",
    "\n",
    "df01 = (df0.assign(tagnames = df0['tagnames'].str.split(','))\n",
    "         .explode('tagnames')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "print(len(df01.index))\n",
    "# print(len(df01.index))\n",
    "value_list = ['hdl']\n",
    "df_dominant_topic_final = df01[df01['tagnames'].isin(value_list)]\n",
    "\n",
    "print(len(df_dominant_topic_final.index))\n",
    "###########################################\n",
    "df_dominant_topic_final.ACCanswerBody.isna().sum()\n",
    "\n",
    "df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n",
    "\n",
    "\n",
    "\n",
    "df_dominant_topic_final.IsAcceptedAnswer.value_counts(normalize=True)      \n",
    "\n",
    "accepted_answers_percentage = df_dominant_topic_final.groupby(['Dominant_Topic','IsAcceptedAnswer']).size().reset_index(name='count')\n",
    "# Change: groupby state_office and divide by sum\n",
    "tmp_df = accepted_answers_percentage.groupby('Dominant_Topic').agg({'count': 'sum'}).reset_index()\n",
    "tmp_df = pd.merge(accepted_answers_percentage , tmp_df , on='Dominant_Topic' ,how='inner')\n",
    "tmp_df['percentage'] = (tmp_df['count_x']/tmp_df['count_y'])*100\n",
    "accepted_answers_percentage = tmp_df[['Dominant_Topic','IsAcceptedAnswer','percentage']]\n",
    "not_accepted_answer = accepted_answers_percentage[accepted_answers_percentage['IsAcceptedAnswer']==False]\n",
    "not_accepted_answer.to_excel('Not accepted answer percentage per topic.xlsx',index=False)\n",
    "print(not_accepted_answer)\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x = 'Dominant_Topic', y = 'percentage', data = not_accepted_answer,\n",
    "            palette = 'Blues', edgecolor = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "df0 = pd.read_csv (r'Topic_modeling_result_HDL.csv',parse_dates=['AcceptedAnswerdate','creationdate'])\n",
    "print(len(df0.index))\n",
    "\n",
    "\n",
    "df01 = (df0.assign(tagnames = df0['tagnames'].str.split(','))\n",
    "         .explode('tagnames')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "print(len(df01.index))\n",
    "print(len(df01.index))\n",
    "value_list = ['vhdl']\n",
    "df_dominant_topic_final = df01[df01['tagnames'].isin(value_list)]\n",
    "\n",
    "print(len(df_dominant_topic_final.index))\n",
    "###########################################\n",
    "df_dominant_topic_final.ACCanswerBody.isna().sum()\n",
    "\n",
    "df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n",
    "\n",
    "\n",
    "\n",
    "df_dominant_topic_final.IsAcceptedAnswer.value_counts(normalize=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30446a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "df0 = pd.read_csv (r'Topic_modeling_result_HDL.csv',parse_dates=['AcceptedAnswerdate','creationdate'])\n",
    "print(len(df0.index))\n",
    "\n",
    "\n",
    "df01 = (df0.assign(tagnames = df0['tagnames'].str.split(','))\n",
    "         .explode('tagnames')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "print(len(df01.index))\n",
    "print(len(df01.index))\n",
    "value_list = ['verilog']\n",
    "df_dominant_topic_final = df01[df01['tagnames'].isin(value_list)]\n",
    "\n",
    "print(len(df_dominant_topic_final.index))\n",
    "###########################################\n",
    "df_dominant_topic_final.ACCanswerBody.isna().sum()\n",
    "\n",
    "df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n",
    "\n",
    "\n",
    "\n",
    "df_dominant_topic_final.IsAcceptedAnswer.value_counts(normalize=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff2e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3399\n",
      "3867\n",
      "3867\n",
      "310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f3dd55817935>:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     0.53871\n",
       "False    0.46129\n",
       "Name: IsAcceptedAnswer, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "df0 = pd.read_csv (r'Topic_modeling_result_HDL.csv',parse_dates=['AcceptedAnswerdate','creationdate'])\n",
    "print(len(df0.index))\n",
    "\n",
    "\n",
    "df01 = (df0.assign(tagnames = df0['tagnames'].str.split(','))\n",
    "         .explode('tagnames')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "print(len(df01.index))\n",
    "print(len(df01.index))\n",
    "value_list = ['system-verilog']\n",
    "df_dominant_topic_final = df01[df01['tagnames'].isin(value_list)]\n",
    "\n",
    "print(len(df_dominant_topic_final.index))\n",
    "###########################################\n",
    "df_dominant_topic_final.ACCanswerBody.isna().sum()\n",
    "\n",
    "df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n",
    "\n",
    "\n",
    "\n",
    "df_dominant_topic_final.IsAcceptedAnswer.value_counts(normalize=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c5320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3399\n",
      "3867\n",
      "3867\n",
      "240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-ffcc58bb3358>:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     0.541667\n",
       "False    0.458333\n",
       "Name: IsAcceptedAnswer, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','like' 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','py','gt','lt'])\n",
    "char_list = ['=', '+','-','*','<','>','/',')','(','[',']',':'] \n",
    "\n",
    "import gensim\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import os \n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "df0 = pd.read_csv (r'Topic_modeling_result_HDL.csv',parse_dates=['AcceptedAnswerdate','creationdate'])\n",
    "print(len(df0.index))\n",
    "\n",
    "\n",
    "df01 = (df0.assign(tagnames = df0['tagnames'].str.split(','))\n",
    "         .explode('tagnames')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "print(len(df01.index))\n",
    "print(len(df01.index))\n",
    "value_list = ['hdl']\n",
    "df_dominant_topic_final = df01[df01['tagnames'].isin(value_list)]\n",
    "\n",
    "print(len(df_dominant_topic_final.index))\n",
    "###########################################\n",
    "df_dominant_topic_final.ACCanswerBody.isna().sum()\n",
    "\n",
    "df_dominant_topic_final['IsAcceptedAnswer']=df_dominant_topic_final['ACCanswerBody'].apply(lambda x:False if x == ' ' else True )\n",
    "\n",
    "\n",
    "\n",
    "df_dominant_topic_final.IsAcceptedAnswer.value_counts(normalize=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea363ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
